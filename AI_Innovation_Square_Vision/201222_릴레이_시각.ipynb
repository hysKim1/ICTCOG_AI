{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## object detection\n",
    "- 영상처리에서 가장 중요\n",
    "- 딥러닝통해서 가장 많은 성능 향상을 이룸\n",
    "-  사람만큼 빠르고 정확함\n",
    "\n",
    "주된 이미지?\n",
    "- 가장 큰 부분을 차지하고 중앙에 위치\n",
    "\n",
    "\n",
    "1. classification\n",
    "2. object detection\n",
    "    - classification + localization\n",
    "    - 사각형 영역에 무엇이 어디에 있는지\n",
    "    - multiple, single object\n",
    "3. Segmentation\n",
    "    - 점 단위로 영역 찾음\n",
    "    - smantic\n",
    "        - 같은 클래스는 하나로 간주\n",
    "    - instance segmentation\n",
    "        - 인스턴스별로 구분\n",
    "        \n",
    "        \n",
    "### Convolution Neural Network\n",
    "- 2 stage 찾고 분류    \n",
    "    - 높은 **정확도**\n",
    "    - Faster R-CNN\n",
    "- 1 stage 동시에 찾으면서 분류\n",
    "    - 빠른 **속도**\n",
    "    - YOLO\n",
    "    \n",
    "### R-CNN    \n",
    "#### Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation\n",
    "- 처음으로 detection에 CNN 적용\n",
    "\n",
    "\n",
    "절차\n",
    "1. 이미지 입력\n",
    "2. selective search \n",
    "        - 4가지 기준\n",
    "        -  hierarchial clustering 과 유사 뮬채거 았을 만한 그럴듯한 영역 2000개 추천\n",
    "\n",
    "3. 영역을 CNN에 입력\n",
    "    - 서로 다른 영역을 고정된 크기로 넣어야해서 **resize, crop **\n",
    "    - 데이터 왜곡\n",
    "4. CNN\n",
    "    - 당시 CNN에대한 불신\n",
    "    - Alex-net\n",
    "\n",
    "5. SVM \n",
    "    - 예측한게 맞는지 다시 확인\n",
    "- 느린 속도\n",
    "\n",
    "- 검정: intersection of Union 겹치는 영역으로 b-box 성능 체크\n",
    "\n",
    "1. Module Design\n",
    "    -  모듈별로 각각의 역할을 함\n",
    "    - <> end-to-end model\n",
    "    - 병목현상 줄얻듦\n",
    "    - 각 모델을 검정함\n",
    "b-box regression  multi-output    \n",
    "    \n",
    "    \n",
    "### SPP-net\n",
    "#### Convolutional Neural Networks for Visual Recognition\n",
    "- 절차를 바꾸어 crop, resize불필요\n",
    "\n",
    "1. image입력\n",
    "2. CNN\n",
    "    - 이미지 입력 크기 상관 없음\n",
    "3. selective search 사용해서 RP 찾음\n",
    "4. Spatical pyramid pooling\n",
    "    - 1,2,4 등분\n",
    "    - 자연어 처리 BoW(Bag of Words확장판\n",
    "    - Spatial pyramid matching\n",
    "        - 최빈값으로 각 영역의 대표값 사용\n",
    "        - MaxPooling과 동일한 역할\n",
    "        - 크기가 상이한 이미지라도 pooling하면 크기가 동일하게됨\n",
    "4. 예판\n",
    "\n",
    "> ZFnet: Convolution fine tunning \n",
    "\n",
    "- Feature map에서 특징 부분이 가장 activation이 강함\n",
    "- feature map과 detection영역이 상관 있음을 알수 있음\n",
    "\n",
    "\n",
    "속도향상에 집중함\n",
    "\n",
    "### Fast R-CNN\n",
    "#### Fast R-CNN\n",
    "- SPP-net ,R-CNN 단점\n",
    "    - multi-stage pipeline\n",
    "        - R-CNN, SVM. B-boxt regressor\n",
    "    - 학습 속도와 저장 비효율성 \n",
    "    - obejct detection selective search로 느림\n",
    "장점\n",
    "- 빠름\n",
    "- **multi-task loss**\n",
    "    -  classification & localization(b-box regressor)을 한번에 학습\n",
    "    - 학습이 잘 안됨\n",
    "    > GAN 학습이 잘 안됨\n",
    "- 학습시 모든 네트워크 레이어 없데이트 가능\n",
    "    - 병목현상을 줄이므로 속도 향상\n",
    "- 피쳐 캐슁 불필요\n",
    "단점\n",
    "\n",
    "\n",
    "SVM 대신 NN기반\n",
    "- Region proposal: selective search \n",
    "- convolution \n",
    "- RoI Pooling :Region of interest 관심영역 부분까지 학습 시켜서 찾음\n",
    "    - 이미지 크기 상관없이 입력 바아서 동일한 크기로 만들어줌\n",
    "    - single level SPP-layer 로 7x7\n",
    "    - 빨느 계산 \n",
    "- mapping   \n",
    "> 하나의 레잉어에서 멀티아웃풋 가능 resnet\n",
    "keras.js\n",
    "### Faster R-CNN\n",
    "### 생성, AE,VAE\n",
    "#### Faster R-CNN\n",
    "### Mask R-CNN\n",
    "### YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- convolution의 특징\n",
    "    - 특성 추출\n",
    "    - 위치 정보를 갖고 있음\n",
    "\n",
    "- Alexnet convolutoin 도입\n",
    "- ZFnet 특징, 클래스 연관관계 통해 커스터마이징\n",
    "- SPP-net 컨볼루션이 가장크게활성화된 부분이 실제 위치와 관련있다. \n",
    "\n",
    "\n",
    "2016\n",
    "selective search도 학습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.applications.MobileNetV2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model #모델 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- multi-inputs,outputs 레이어 형태\n",
    "    - Resnet, GooLeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
