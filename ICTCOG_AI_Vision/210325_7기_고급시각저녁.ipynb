{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "210325_7기_고급시각저녁",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMlC5NHltE5k"
      },
      "source": [
        "# [ICTCOG AI Academy] 7기 고급시각저녁반\n",
        "# Review\n",
        "### AI Index Report 2021\n",
        "#### Computer Vision 방향\n",
        "  - Resnet이 인간을 뛰어넘었기 때문에 이제는 경령화\n",
        "- 퍼포먼스는 고원현상에 도달함\n",
        "- GPU, 분산처리를 통해 성능 개선, 학습 시간, cost 축소\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbihqEf3yUR_"
      },
      "source": [
        "### Review\n",
        "#### 1. 이미지 데이터 Load "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A795AYzGtH68"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nqV0Wx0ysKd"
      },
      "source": [
        "#tensorflow에서 제공하는 최고의 performance :tf.data.Dataset, tf.function\n",
        "tf.keras.preprocessing.image_dataset_from_directory\n",
        "tf.keras.preprocessing.image.ImageDataGenerator\n",
        "tf.io.read_file\n",
        "tf.io.decode_jpeg #여러가지"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2o4YRuuptIDy"
      },
      "source": [
        "#### 단점\n",
        "- 범용성이 Numpy 보다 떨어짐\n",
        "  - 다양한 프레임워크 사용하기에 복잡함\n",
        "- 난이도\n",
        "  - 핑수적 기능 외에 추가 기능이 비교적 적어서 직접 만듦어야함"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFlZJA2bzlXW"
      },
      "source": [
        "기타 Numpy 호환 Library\n",
        "- imageio\n",
        "- Scipy\n",
        "- scikit-image\n",
        "- opencv\n",
        "- PIL\n",
        "  - Tensorflow, PyTorch에서 내부적으로 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJy4w6Nr0Ds8"
      },
      "source": [
        "### 2. 모델 \n",
        "- Functional programming + OOP(객체지향)\n",
        "\n",
        "1. tf.nn \n",
        "  - from scartch\n",
        "2. tf.estimator\n",
        "  - greaident based model\n",
        "3. tf.keras.models.Sequential\n",
        "  - 단방향\n",
        "4. tf.keras.models.Model\n",
        "  - multi-inputs, multi-outputs\n",
        "5. tf.keras.models.Model 상속\n",
        "  - 제공하지 않는 모델 만들때 사용\n",
        "\n",
        "> 모델 구성에는 답이 없음\n",
        "  - \"...안타깝지만 어떤 모델의 (층의 개수나 뉴런 개수에 해당하는) 적절한 크기나 구조를 결정하는 마법같은 공식은 없습니다. \""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLnUqjyb1frH"
      },
      "source": [
        "### 모델\n",
        "- 논문 직접 구현\n",
        "- 이미 만들어진 모델 가져다가 사용\n",
        "  - Model Zoo\n",
        "  - Awsome ___\n",
        "  - Paperwithcode(sota)\n",
        "  - tensorflow addons\n",
        "#### Transfer Learining\n",
        "- feature extractor, fine-tuning\n",
        "  - 유사도와 데이터 양에 따라서 형태 결정\n",
        "  - 모델의 일부를 가져다 쓰는 경우 많았음"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu7-KxPh5QA4"
      },
      "source": [
        "- customizing 필요 \n",
        " - learning technique\n",
        " - compile 의 loss, optimizer \n",
        "  - 기존에 만들어진 것 사용하거나 직접 구현 필요"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44UTGmFPqRMM"
      },
      "source": [
        "model.compile( \n",
        "    optimizer=keras.optimizers.RMSprop(),  # Optimizer\n",
        "    # Loss function to minimize\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "    # List of metrics to monitor\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()],)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zlPzsdx3nnv"
      },
      "source": [
        "### 3.성능 높이기\n",
        "### Data Augmentation\n",
        "- 기존의 데이터를 이용해서 가짜 데이터 생성\n",
        "  - jittering( random cropping , flipping, rotating)\n",
        "- 모델 성능향상보다는 overfitting 방지용\n",
        "\n",
        "### 4.Learning technique \n",
        "- fit\n",
        "- fit_generator\n",
        "- train_on_batch\n",
        "- **tf.GradientTape**\n",
        "  - with 구문과 사용\n",
        "  - 직접 구현\n",
        "- train from estimator\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKyha_NX4uzo"
      },
      "source": [
        "---\n",
        "### A.Obejct Detection\n",
        "- 사람을 뛰어넘음\n",
        "#### 1 stage\n",
        "- YOLO v1,v2,v3,v4,v5\n",
        "  > 참고 :https://pjreddie.com/darknet/yolo/\n",
        "- 빠른 속도\n",
        "- 활용: real-time detection\n",
        "\n",
        "#### 2 stage\n",
        "- R-CNN, SPPnet, Fast R-CNN, Faster R-CNN\n",
        "- 높은 성능 \n",
        "- 활용: Data Annotation(Object Detection)\n",
        "\n",
        "\n",
        "### B.Segmentation\n",
        "\n",
        "#### Semantic Segmentation, Instance Segmentation\n",
        "- 픽셀 단위로 recognition\n",
        "- 같은 픽셀끼리 합침\n",
        "\n",
        "\n",
        "### C.Generation\n",
        "- AutoEncoder, VAE, **GAN** 활용\n",
        "> - 활용 테크닉 leaky relu, 다양한 normalization \n",
        "- VAE  \n",
        "- GAN  흐릿함\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKu6ysuREnYU"
      },
      "source": [
        "> python 2에서 3  버전 호환이 되지 않아서 six library 사용 \n",
        "- segmentation, detection 은 이미지와 annotation 파일까지 필요함\n",
        "  - annotation tool도 필요함\n",
        "  - 기존의것 재학습 하는 경우가 많음 \n",
        "- 참고 : https://github.com/tensorflow/hub/blob/master/examples/colab/tf2_object_detection.ipynb \n",
        "\n",
        "- 컨볼루션 사용해서 크기를 줄이고 원본 영역을 찾아야하므로 원래 크기로 복원 \n",
        "  - feature extraction + generation 기법 \n",
        "\n",
        "#### [Segmentation](https://www.tensorflow.org/tutorials/images/segmentation?hl=ko)\n",
        "U-net\n",
        "- 컨볼루션을 통해 잃어버린 detail을 skip connection으로 받아옴\n",
        "- 복원 시 더 잘 복원됨\n",
        "\n",
        "\n",
        "- pipeline 구성 시 효율적 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQWNoln7z9j0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0df83bf-0ca1-4864-e836-6159eac89928"
      },
      "source": [
        "!pip install -q git+https://github.com/tensorflow/examples.git\n",
        "!pip install -q -U tfds-nightly"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for tensorflow-examples (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 4.5MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXxNJ5LxHKOK"
      },
      "source": [
        "from tensorflow_examples.models.pix2pix import pix2pix\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hX441JyZHRg0",
        "outputId": "6d1c4182-1eaa-40c2-8ab5-a2daba6deb27"
      },
      "source": [
        "dataset, info = tfds.load('oxford_iiit_pet:3.*.*', with_info=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset 773.52 MiB (download: 773.52 MiB, generated: 774.69 MiB, total: 1.51 GiB) to /root/tensorflow_datasets/oxford_iiit_pet/3.2.0...\u001b[0m\n",
            "\u001b[1mDataset oxford_iiit_pet downloaded and prepared to /root/tensorflow_datasets/oxford_iiit_pet/3.2.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uq_CXcaHHS-e"
      },
      "source": [
        "def normalize(input_image, input_mask):\n",
        "  input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "  input_mask -= 1\n",
        "  return input_image, input_mask\n",
        "\n",
        "@tf.function\n",
        "def load_image_train(datapoint):\n",
        "  input_image = tf.image.resize(datapoint['image'], (128, 128))\n",
        "  input_mask = tf.image.resize(datapoint['segmentation_mask'], (128, 128))\n",
        "\n",
        "  if tf.random.uniform(()) > 0.5:\n",
        "    input_image = tf.image.flip_left_right(input_image)\n",
        "    input_mask = tf.image.flip_left_right(input_mask)\n",
        "\n",
        "  input_image, input_mask = normalize(input_image, input_mask)\n",
        "\n",
        "  return input_image, input_mask"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcLlXur_HWPD"
      },
      "source": [
        "def load_image_test(datapoint):\n",
        "  input_image = tf.image.resize(datapoint['image'], (128, 128))\n",
        "  input_mask = tf.image.resize(datapoint['segmentation_mask'], (128, 128))\n",
        "\n",
        "  input_image, input_mask = normalize(input_image, input_mask)\n",
        "\n",
        "  return input_image, input_mask"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAX6MauiIIzd"
      },
      "source": [
        "TRAIN_LENGTH = info.splits['train'].num_examples\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 1000\n",
        "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n",
        "#map 적용\n",
        "train = dataset['train'].map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "test = dataset['test'].map(load_image_test)\n",
        "# 최적화\n",
        "train_dataset = train.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = test.batch(BATCH_SIZE)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8FKIQN-Hdat"
      },
      "source": [
        "### U-net\n",
        "- MobileNetV2 Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgekujNWHX2M",
        "outputId": "2661855a-9313-4e96-90f2-10fa5682c36a"
      },
      "source": [
        "OUTPUT_CHANNELS = 3\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=[128, 128, 3], include_top=False)\n",
        "\n",
        "#이 층들의 활성화를 이용합시다\n",
        "layer_names = [\n",
        "    'block_1_expand_relu',   # 64x64\n",
        "    'block_3_expand_relu',   # 32x32\n",
        "    'block_6_expand_relu',   # 16x16\n",
        "    'block_13_expand_relu',  # 8x8\n",
        "    'block_16_project',      # 4x4\n",
        "]\n",
        "layers = [base_model.get_layer(name).output for name in layer_names]\n",
        "\n",
        "# 특징추출 모델을 만듭시다\n",
        "down_stack = tf.keras.Model(inputs=base_model.input, outputs=layers)\n",
        "\n",
        "down_stack.trainable = False"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_128_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8J6sIfQnHc2I"
      },
      "source": [
        "up_stack = [\n",
        "    pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n",
        "    pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n",
        "    pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n",
        "    pix2pix.upsample(64, 3),   # 32x32 -> 64x64\n",
        "]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRfNhffMHnb0"
      },
      "source": [
        "def unet_model(output_channels):\n",
        "  inputs = tf.keras.layers.Input(shape=[128, 128, 3])\n",
        "  x = inputs\n",
        "\n",
        "  # 다운샘플링\n",
        "  skips = down_stack(x)\n",
        "  x = skips[-1]\n",
        "  skips = reversed(skips[:-1])  #reverse 해서 순서 바꿈 \n",
        "\n",
        "  # skip connection , 업샘플링ef unet_model(output_channels):\n",
        "  for up, skip in zip(up_stack, skips):\n",
        "    x = up(x)\n",
        "    concat = tf.keras.layers.Concatenate()\n",
        "    x = concat([x, skip])\n",
        "\n",
        "  # 이 모델의 마지막 층입니다\n",
        "  last = tf.keras.layers.Conv2DTranspose(\n",
        "      output_channels, 3, strides=2,\n",
        "      padding='same')  #64x64 -> 128x128\n",
        "\n",
        "  x = last(x)\n",
        "\n",
        "  return tf.keras.Model(inputs=inputs, outputs=x)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH8Fh54YHpIi"
      },
      "source": [
        "model = unet_model(OUTPUT_CHANNELS)\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),  #numerical stability \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3Aat313IESm"
      },
      "source": [
        "class DisplayCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    clear_output(wait=True)\n",
        "    show_predictions()\n",
        "    print ('\\n에포크 이후 예측 예시 {}\\n'.format(epoch+1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h7GuLy8IwVl"
      },
      "source": [
        "EPOCHS = 20\n",
        "VAL_SUBSPLITS = 5\n",
        "VALIDATION_STEPS = info.splits['test'].num_examples//BATCH_SIZE//VAL_SUBSPLITS\n",
        "\n",
        "model.fit(train_dataset, epochs=EPOCHS,\n",
        "                          steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                          validation_steps=VALIDATION_STEPS,\n",
        "                          validation_data=test_dataset,\n",
        "                          callbacks=[DisplayCallback()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZH2UX5iIzye"
      },
      "source": [
        "functional paradigm  , OOP 적용 되어 있음\n",
        "### 복습\n",
        "1. 데이터를 불러오기\n",
        "2. 이미지 데이터 EDA\n",
        "3. normalization\n",
        "  - [0,1] , [-1,1] \n",
        "4. 모델 구조 정하기\n",
        "  - 모델 상속 \n",
        "  - data augmentation 은 먼저 학습해보고 overfitting 생기면 적용\n",
        "- Tensorflow 하드웨어 지원 최대화 가능\n",
        "\n",
        "참고 : https://www.tensorflow.org/tutorials/quickstart/advanced?hl=ko"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgsXUGxaK9E8"
      },
      "source": [
        "class MyModel(Model): #상속\n",
        "  def __init__(self):\n",
        "    super(MyModel, self).__init__()\n",
        "    self.conv1 = Conv2D(32, 3, activation='relu')\n",
        "    self.flatten = Flatten()\n",
        "    self.d1 = Dense(128, activation='relu')\n",
        "    self.d2 = Dense(10, activation='softmax')\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.d1(x)\n",
        "    return self.d2(x)\n",
        "\n",
        "model = MyModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68aZZ3pbK-4a"
      },
      "source": [
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "  with tf.GradientTape() as tape:  #gradient tape \n",
        "    predictions = model(images)\n",
        "    loss = loss_object(labels, predictions)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_loss(loss)\n",
        "  train_accuracy(labels, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkc7ZK5eLEwn"
      },
      "source": [
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "  predictions = model(images)\n",
        "  t_loss = loss_object(labels, predictions)\n",
        "\n",
        "  test_loss(t_loss)\n",
        "  test_accuracy(labels, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRo90HFbLEyx"
      },
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  for images, labels in train_ds:\n",
        "    train_step(images, labels)\n",
        "\n",
        "  for test_images, test_labels in test_ds:\n",
        "    test_step(test_images, test_labels)\n",
        "\n",
        "  template = '에포크: {}, 손실: {}, 정확도: {}, 테스트 손실: {}, 테스트 정확도: {}'\n",
        "  print (template.format(epoch+1,\n",
        "                         train_loss.result(),\n",
        "                         train_accuracy.result()*100,\n",
        "                         test_loss.result(),\n",
        "                         test_accuracy.result()*100))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}