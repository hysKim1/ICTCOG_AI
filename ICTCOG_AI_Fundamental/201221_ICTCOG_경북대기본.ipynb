{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ICTCOG] 4기 경북대 기본반\n",
    "\n",
    "## 딥러닝 (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "boston=pd.DataFrame(data.data ,columns=data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston['target']= data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     506 non-null    float64\n",
      " 1   ZN       506 non-null    float64\n",
      " 2   INDUS    506 non-null    float64\n",
      " 3   CHAS     506 non-null    float64\n",
      " 4   NOX      506 non-null    float64\n",
      " 5   RM       506 non-null    float64\n",
      " 6   AGE      506 non-null    float64\n",
      " 7   DIS      506 non-null    float64\n",
      " 8   RAD      506 non-null    float64\n",
      " 9   TAX      506 non-null    float64\n",
      " 10  PTRATIO  506 non-null    float64\n",
      " 11  B        506 non-null    float64\n",
      " 12  LSTAT    506 non-null    float64\n",
      " 13  target   506 non-null    float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 55.5 KB\n"
     ]
    }
   ],
   "source": [
    "boston.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- scikit-learn 은 기본값 설정이 되어 있어서 자동으로 맞추어 줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp=MLPRegressor((100,100,100)) #100 개 perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/MG/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(hidden_layer_sizes=(100, 100, 100))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(boston.iloc[:,:-1], boston.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boston_model():\n",
    "    model=tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(100,input_shape=(13,), activation='relu'),\n",
    "        tf.keras.layers.Dense(100,'relu'),\n",
    "        tf.keras.layers.Dense(100,'relu'),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=boston_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 334.7250\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 88.2351\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 67.2931\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 60.9751\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 60.7141\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 60.8786\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 56.1867\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 56.7341\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 2ms/step - loss: 53.1501\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 52.2698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd90cd3c950>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(boston.iloc[:,:-1], boston.target, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wrappers.scikit_learn \n",
    "- Scikit-learn에서 제공하는 기능을 Tensorflow에서 사용 가능\n",
    "- GPU 사용가능 \n",
    "\n",
    "#### KerasRegressor\n",
    "- scikit-learn Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kr=KerasRegressor(boston_model, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 123.0780\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 64.7746\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 62.9065\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 64.5202\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 61.6190\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 59.2879\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 54.5542\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 54.8999\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 52.1623\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 47.0459\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 31.5781\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 103.2359\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 63.4799\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 59.2189\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 57.1793\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 54.3111\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 54.4048\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 54.6164\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 59.7820\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 52.4045\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 44.4715\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 24.7860\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 180.5356\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 78.3656\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 78.9026\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 66.0494\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 55.5666\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 63.9052\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 57.1571\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 56.3460\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 52.1068\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 47.0172\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 20.7000\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 689.3636\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 95.3648\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 62.9322\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 58.5354\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 63.2398\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 55.9234\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 53.9793\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 53.1766\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 55.8690\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 59.2622\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 103.5490\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 116.8089\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 61.1260\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 59.4194\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 56.2872\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 53.8854\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 57.1675\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 52.9485\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 59.6152\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 52.1219\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 47.3531\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd90cb597a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 102.9171\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 581.3119\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 130.4015\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 66.1859\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 59.8100\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 56.7913\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 55.5823\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 53.9903\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 53.9080\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 53.2204\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 53.2222\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd90e1a2f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 92.4538\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 123.8892\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 71.1183\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 73.7160\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 74.2966\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 71.7789\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 62.4687\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 56.8255\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 57.6007\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 64.2801\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 62.2961\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd90db78320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 37.8545\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 292.3728\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 66.9455\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 57.4875\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 50.6850\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 53.8463\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 53.2800\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 48.5658\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 47.1575\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 43.8383\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 45.2842\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd90e4053b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 158.7913\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 159.2668\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 66.0604\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 64.0888\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 60.2333\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 58.8201\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 64.9208\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 64.5261\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 63.7878\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 52.7716\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 56.1974\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd905579a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 37.0153\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 1728.8014\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 178.1284\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 95.2247\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 70.5991\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 65.3936\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 63.8490\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 63.1036\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 62.0435\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 61.1490\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 61.2716\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd90efab5f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.1282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ -31.5781002 ,  -24.78600502,  -20.6999855 , -103.54901123,\n",
       "       -102.91705322,  -92.4537735 ,  -37.85450745, -158.79133606,\n",
       "        -37.01533127,  -18.12818909])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(kr, boston.iloc[:,:-1],boston.target, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KerasClassifier\n",
    "- scikit-learn classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=load_wine()\n",
    "wine=pd.DataFrame(data.data, columns=data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine['target']=data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178 entries, 0 to 177\n",
      "Data columns (total 14 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   alcohol                       178 non-null    float64\n",
      " 1   malic_acid                    178 non-null    float64\n",
      " 2   ash                           178 non-null    float64\n",
      " 3   alcalinity_of_ash             178 non-null    float64\n",
      " 4   magnesium                     178 non-null    float64\n",
      " 5   total_phenols                 178 non-null    float64\n",
      " 6   flavanoids                    178 non-null    float64\n",
      " 7   nonflavanoid_phenols          178 non-null    float64\n",
      " 8   proanthocyanins               178 non-null    float64\n",
      " 9   color_intensity               178 non-null    float64\n",
      " 10  hue                           178 non-null    float64\n",
      " 11  od280/od315_of_diluted_wines  178 non-null    float64\n",
      " 12  proline                       178 non-null    float64\n",
      " 13  target                        178 non-null    int64  \n",
      "dtypes: float64(13), int64(1)\n",
      "memory usage: 19.6 KB\n"
     ]
    }
   ],
   "source": [
    "wine.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    71\n",
       "0    59\n",
       "2    48\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.target.value_counts() # classification : labels 3 개 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fn():\n",
    "    model=tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(100,input_shape=(13,), activation='relu'),\n",
    "        tf.keras.layers.Dense(100,activation='relu'),\n",
    "        tf.keras.layers.Dense(100,activation='relu'),\n",
    "        tf.keras.layers.Dense(3,activation='softmax')\n",
    "    ])\n",
    "    model.compile(loss='sparse_catagorical_crossentropy', \n",
    "                  optimizer='adam',  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "kc=tf.keras.wrappers.scikit_learn.KerasClassifier(build_fn, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')  #경고 메시지 무시하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(kc, wine.iloc[:,:-1],wine.target, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn의 grid search CV도 tensorflow에서 사용 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## callbacks\n",
    "- 학습단계에서 다양한 이벤트들에 대해서 미리 만들어진 기능 제공\n",
    "### on_epoch_begin, on_epoch_end\n",
    "- epoch 한번 시작/끝 날때마다 결과 저장해놓아서 실수할 떄 복구 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tf.keras.callbacks.Callback )#class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_implements_predict_batch_hooks',\n",
       " '_implements_test_batch_hooks',\n",
       " '_implements_train_batch_hooks',\n",
       " '_keras_api_names',\n",
       " '_keras_api_names_v1',\n",
       " 'on_batch_begin',\n",
       " 'on_batch_end',\n",
       " 'on_epoch_begin',\n",
       " 'on_epoch_end',\n",
       " 'on_predict_batch_begin',\n",
       " 'on_predict_batch_end',\n",
       " 'on_predict_begin',\n",
       " 'on_predict_end',\n",
       " 'on_test_batch_begin',\n",
       " 'on_test_batch_end',\n",
       " 'on_test_begin',\n",
       " 'on_test_end',\n",
       " 'on_train_batch_begin',\n",
       " 'on_train_batch_end',\n",
       " 'on_train_begin',\n",
       " 'on_train_end',\n",
       " 'set_model',\n",
       " 'set_params']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tf.keras.callbacks.Callback )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.callbacks.Callback.on_epoch_begin\n",
    "tf.keras.callbacks.Callback.on_epoch_end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 싱속\n",
    "- 오버라이딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCallBack(tf.keras.callbacks.Callback): \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        print('Begin!!!!!!!!')\n",
    "    def on_epoch_end(self,epoch,logs=None):\n",
    "        print('   end..........')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin!!!!!!!!\n",
      "Epoch 1/5\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.2852   end..........\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4516\n",
      "Begin!!!!!!!!\n",
      "Epoch 2/5\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.4216   end..........\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4426\n",
      "Begin!!!!!!!!\n",
      "Epoch 3/5\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.4066   end..........\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4425\n",
      "Begin!!!!!!!!\n",
      "Epoch 4/5\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.4354   end..........\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4388\n",
      "Begin!!!!!!!!\n",
      "Epoch 5/5\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.4463   end..........\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd90efdfd10>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit( wine.iloc[:,:-1],wine.target, epochs=5, \n",
    "          callbacks=[MyCallBack()]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSVLogger\n",
    "- 1 epoch 당 결과를 csv로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv=tf.keras.callbacks.CSVLogger('a.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin!!!!!!!!\n",
      "Epoch 1/5\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.5253   end..........\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4356\n",
      "Begin!!!!!!!!\n",
      "Epoch 2/5\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.4324   end..........\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4332\n",
      "Begin!!!!!!!!\n",
      "Epoch 3/5\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.4811   end..........\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4360\n",
      "Begin!!!!!!!!\n",
      "Epoch 4/5\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.5855   end..........\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4424\n",
      "Begin!!!!!!!!\n",
      "Epoch 5/5\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.4319   end..........\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4498\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd90ef4a110>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit( wine.iloc[:,:-1],wine.target, epochs=5, callbacks=[MyCallBack() , csv])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard\n",
    "- 모델, 학습 관련 시각화\n",
    "\n",
    "- Scalar: 성능 평가\n",
    "- GRAPHS : computational graph 모델 시각화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb= tf.keras.callbacks.TensorBoard( log_dir='tttt' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin!!!!!!!!\n",
      "Epoch 1/5\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.2382WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0046s vs `on_train_batch_end` time: 0.0270s). Check your callbacks.\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.4252   end..........\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4252\n",
      "Begin!!!!!!!!\n",
      "Epoch 2/5\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.2837   end..........\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4217\n",
      "Begin!!!!!!!!\n",
      "Epoch 3/5\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.4258   end..........\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.4204\n",
      "Begin!!!!!!!!\n",
      "Epoch 4/5\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.4807   end..........\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4404\n",
      "Begin!!!!!!!!\n",
      "Epoch 5/5\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 0.4775   end..........\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.4234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd90558d750>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit( wine.iloc[:,:-1],wine.target, epochs=5, callbacks=[MyCallBack() , tb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1221 19:28:19.887557 123145357496320 plugin_event_accumulator.py:323] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.3.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir='tttt' #하단의 링크로 이동  ->  kernel 멈추기 전까 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터와 경로 동일해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4d85834daa928841\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4d85834daa928841\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir tttt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 저장과 복원\n",
    "> - pickle 객체 저장 \n",
    "    - Python 고유 format이라서 다른 언어에서 읽을 수 없음\n",
    "- 범용 format 이용해서 데이터 저장 \n",
    "\n",
    "\n",
    "### HDF5\n",
    "- HDF5(Hierachial Data Format)계층적 데이터 포맷\n",
    "    - 범용적\n",
    "\n",
    "참고: https://www.tensorflow.org/tutorials/keras/save_and_load?hl=ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- holdout\n",
    "- 각 train, test 데이터엣 1000개씩 샘플링\n",
    "- 1차원화\n",
    "    - > Flatten 모델 내에서 1차원화 \n",
    "- scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_labels = train_labels[:1000]\n",
    "test_labels = test_labels[:1000]\n",
    "\n",
    "train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0\n",
    "test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- overfitting 학습한 데이터에서는 성능이 좋으나 처음보는 데이터에서는 성능이 좋지않음\n",
    "- 딥러닝 모델이 기본적으로 복잡해서 과적합 잘 남\n",
    "\n",
    "### Dropout\n",
    "- 지정한 백분율만큼 노드를 랜덤하게 없앰(0)\n",
    "- 성능 유지하면서 overfitting 방지\n",
    "    - ensemble boosting 성능 좋지 않은 데이터에 가중치 줌\n",
    "- ensemble 효과 : 랜덤하게 제거해서 여러 모델이 합쳐진거와 같은 효과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fit이 계속 이어서 학습하기 때문에 **함수로 만들어서 재사용**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_84 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 간단한 Sequential 모델 정의\n",
    "def create_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "    keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
    "    keras.layers.Dropout(0.2), #20%를 랜덤하게 제외\n",
    "    keras.layers.Dense(10)\n",
    "  ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# 모델 객체를 생성\n",
    "model = create_model()\n",
    "\n",
    "# 모델 구조를 출력\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ModelCheckpoint\n",
    "- 중요 시점에 저장\n",
    "- training_1 폴더 안에 cp.ckpt 생성됨\n",
    "- epoch 마다 이름이 돌일하여 이전 결과 덮어쓰면서 최종 결과를 pickling 하여 저장\n",
    "- load, dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.callbacks.ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 1.3808 - accuracy: 0.6141WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd8f155fdd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 1.1977 - accuracy: 0.6620 - val_loss: 0.7437 - val_accuracy: 0.7840\n",
      "Epoch 2/10\n",
      "28/32 [=========================>....] - ETA: 0s - loss: 0.4223 - accuracy: 0.8761\n",
      "Epoch 00002: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.4282 - accuracy: 0.8760 - val_loss: 0.5270 - val_accuracy: 0.8410\n",
      "Epoch 3/10\n",
      "23/32 [====================>.........] - ETA: 0s - loss: 0.2962 - accuracy: 0.9253\n",
      "Epoch 00003: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2780 - accuracy: 0.9330 - val_loss: 0.4666 - val_accuracy: 0.8580\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.2094 - accuracy: 0.9510\n",
      "Epoch 00004: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 15ms/step - loss: 0.2094 - accuracy: 0.9510 - val_loss: 0.4379 - val_accuracy: 0.8640\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1573 - accuracy: 0.9650\n",
      "Epoch 00005: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 14ms/step - loss: 0.1573 - accuracy: 0.9650 - val_loss: 0.4292 - val_accuracy: 0.8700\n",
      "Epoch 6/10\n",
      "27/32 [========================>.....] - ETA: 0s - loss: 0.1178 - accuracy: 0.9803\n",
      "Epoch 00006: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.1157 - accuracy: 0.9790 - val_loss: 0.4205 - val_accuracy: 0.8660\n",
      "Epoch 7/10\n",
      "29/32 [==========================>...] - ETA: 0s - loss: 0.0900 - accuracy: 0.9849\n",
      "Epoch 00007: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 13ms/step - loss: 0.0906 - accuracy: 0.9840 - val_loss: 0.4302 - val_accuracy: 0.8640\n",
      "Epoch 8/10\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 0.0709 - accuracy: 0.9917\n",
      "Epoch 00008: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 12ms/step - loss: 0.0706 - accuracy: 0.9920 - val_loss: 0.4081 - val_accuracy: 0.8700\n",
      "Epoch 9/10\n",
      "29/32 [==========================>...] - ETA: 0s - loss: 0.0478 - accuracy: 0.9935\n",
      "Epoch 00009: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0486 - accuracy: 0.9940 - val_loss: 0.4232 - val_accuracy: 0.8670\n",
      "Epoch 10/10\n",
      "30/32 [===========================>..] - ETA: 0s - loss: 0.0358 - accuracy: 1.0000\n",
      "Epoch 00010: saving model to training_1/cp.ckpt\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.4097 - val_accuracy: 0.8710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd8f152bf50>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# 모델의 가중치를 저장\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "# 새로운 콜백으로 모델 훈련\n",
    "model.fit(train_images, train_labels,  epochs=10,\n",
    "          validation_data=(test_images,test_labels),\n",
    "          callbacks=[cp_callback])  \n",
    "\n",
    "# 옵티마이저의 상태를 저장하는 것과 관련되어 경고가 발생할 수 있습니다.\n",
    "# 이 경고는 (그리고 이 노트북의 다른 비슷한 경고는) 이전 사용 방식을 권장하지 않기 위함이며 무시해도 좋습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 5번의 epoch 별로 가중치 저장\n",
    "- 10 epochs -> 2개 파일 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "\n",
      "Epoch 00005: saving model to training_2/cp-0005.ckpt\n",
      "\n",
      "Epoch 00010: saving model to training_2/cp-0010.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd8f18f6a10>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=True,  period=5)\n",
    "\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "# `checkpoint_path` 포맷을 사용하는 가중치를 저장합니다\n",
    "model.save_weights(checkpoint_path.format(epoch=0))\n",
    "\n",
    "# 새로운 콜백을 사용하여 모델을 훈련합니다\n",
    "model.fit(train_images, \n",
    "          train_labels,\n",
    "          epochs=10, \n",
    "          callbacks=[cp_callback],\n",
    "          validation_data=(test_images,test_labels),\n",
    "          verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model.save,load\n",
    "- 전체 모델 저장/불러오기\n",
    "- 구조, weights 등이 pickle, HDF5 저장 \n",
    "\n",
    "### model.save_weights /load_weights\n",
    "- weight 만 저장\n",
    "- HDF5 저장하여 다른 모델, 언어에서 불러와서 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4104 - accuracy: 0.8660\n",
      "복원된 모델의 정확도: 86.60%\n"
     ]
    }
   ],
   "source": [
    "# 가중치를 저장\n",
    "model.save_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "#초기화\n",
    "model = create_model()\n",
    "\n",
    "# 가중치를 복원\n",
    "model.load_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "loss,acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(\"복원된 모델의 정확도: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
